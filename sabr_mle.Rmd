---
title: 'Heston & SABR: YUIMA'
author: "R. Dance"
output:
  html_notebook:
    toc: yes
  pdf_document:
    toc: yes
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

[Link to YUIMA book, see page 85](https://doi.org/10.1007/978-3-319-55569-0)
[Link to reference used in this notebook](https://qfinatwork.com/public/qfin/files/Stefano_Iacus.pdf)
Saved in files "YUIMA_Stefano_Iacus.pdf"
```{r}
library(yuima)
```
## 1D Unparametrised SDE
A simple 1D SDE model for starters with numerical coefficients: 
 $dX_t = -3X_t dt + \frac{1}{1+X_t^2}$
```{r message=FALSE, warning=FALSE}
mod1 <- setModel(drift = "-3*x", diffusion = "1/(1+x^2)")
set.seed(123)
X <- simulate(mod1)
plot(X)
```
Spit out all of the YUIMA model details... (there's a lot so commented it out)
```{r}
#str(X)
```
Summary of X:
```{r}
X
```
## Parametrised model
This time the model has parameters, $\theta$ and $\gamma$:
$dX_t = -\theta X_t dt  + \frac{1}{1+X_t^\gamma} dW_t$

```{r echo=TRUE}
mod2 <- setModel(drift = "-theta*x", diffusion = "1/(1+x^gamma)")
mod2

set.seed(123)
plot(simulate(mod2,true.parameter =list(theta=1,gamma=3)))
```

## Parametrised 1D SDE model, with QMLE
So we want to recover our parameter estimates from their true values.
$dX_t = -\theta_2X_t dt + \theta_1dW_t$

```{r}
diff.matrix <- matrix(c("theta1"), 1, 1) #so apparently dots are ok in names in R... weird.
ymodel <- setModel(drift = c("(-1)*theta2*x"), diffusion = diff.matrix, time.variable = "t", state.variable = "x", solve.variable = "x")
# here you can do plot(simulate(ymodel,true.parameter =list(theta=0.3,gamma=0.1))) to show specific paths at given input params.
# ...this is where the qMLE things specific begin...
n <-100
ysamp <- setSampling(Terminal = (n)^(1/3), n = n) #this expression seems rather arbitrary, 100^1/3 = 4.6?!
yuima <- setYuima(model = ymodel, sampling = ysamp) #yuima - name of package or a variable now?
set.seed(123)
#True values of parameters specified for simulation here, but stay unknown to yuima object?
yuima <- simulate(yuima, xinit = 0.1, true.parameter = list(theta1 = 0.3, theta2 = 0.1))
# now call qmle on yuima object
mle1 <- qmle(yuima, start = list(theta1 = 0.05, theta2 = 0.05), lower = list(theta1=0.001, theta2=0.001), upper = list(theta1=0.5, theta2=0.5), method = "L-BFGS-B")
#print result - can also use just coef(mle1)
summary(mle1)
```
So we got 0.3 which is pretty close, and 0.28 which is not, but it *is* within the standard error.


## 2D parametric Model with qMLE (2-dimensional diffusions with 3 noises)
$dX_t^{(1)} = -\theta_2X_t^{(1)}*dt + dW_t^{(1)} + X_t^{(2)}*dW_t^{(3)}$
$dX_t^{(2)} = -(X_t^1 + \theta_1 X_t^{(2)})dt + X_t^1dW_t^{(1)} + \theta_2dW_t^{(2)}$

```{r echo=TRUE}
sol <- c("x1","x2") # variable for numerical solution 
drifts <- c("-theta2*x1","-x1 - theta1*x2") # drift vectors 
diffs <- matrix(c("1","x1","0","theta2","x2","0"),2,3) # diffusion matrix 
mod3 <- setModel(drift = drifts, diffusion = diffs, solve.variable = sol,time.variable="t", state.variable = sol)
#plotting for 2D on one plot slightly different:
plot(simulate(mod3, true.parameter = list(theta1=2, theta2=3)), plot.type="single", col=c("red","blue"))
```
My main concern here is that I *havent* specified any kind of correlation. This is just two independent processes working away???

```{r}
n <- 100 
mod3samp <- setSampling(Terminal = (n)^(1/3),n = n) 
mod3yuima <- setYuima(model=mod3, sampling = mod3samp) 
set.seed(123)
mod3yuima <- simulate(mod3yuima, xinit=1, true.parameter = list(theta1 = 2,theta2 = 3)) # X is a yuima object
# plot(X,plot.type="single",col=c("red","blue")) 
mle_mod3 <-qmle(mod3yuima, start = list(theta1 = 1.0, theta2 = 1.0),lower = list(theta1=0.05, theta2=0.05), upper = list(theta1=4, theta2=6))
summary(mle_mod3)
```
Why have I got a third parameter? Why is there two theta2?!?!? 

## Heston from the YUIMA book (it has correlation done properly, added qMLE)
$dX_t^{(1)} = \mu X_t^{(1)}dt + \sqrt{X_t^{(2)}}X_t^{(1)}dW_t^{(1)}$

$dX_t^{(2)} = k(\theta - X_t^{(2)})dt + \epsilon\sqrt{X_t^{(2)}}dW_t^{(2)}$

where the Brownians are correlated by some $\rho$ and lets say that we want to use two independent brownians $B_t^{(1)}$ and $B_t^{(2)}$
In order to do this, we need to transform them Cholesky decomposition (Colin, I used a package here!).

The joint distribution of these things (Y) wants to be bivariate normal with correlation matrix $\Sigma$ s.t. $Y\sim N(0,\Sigma)$. So we use Cholesky to find such a matrix that $A^TA=\Sigma$. Then if Z is the standard multivariate normal, then $AZ \sim N(0,\Sigma)$ in the same way as we change brownians to be $\sqrt{dt}.N(0,1)$ all the time. So if we take the correlation matrix, and get the Cholesky decomp of it to get A, we can transform (multiply in normal speak!) the original diffusion matrix so that it works with independent Brownians.

```{r}
rho = 0.7
Sigma <- matrix(c(1.0, rho, rho, 1.0), 2, 2) #I used own values from correlated wieners in python here so S_11 = S_22 = 1 ??
A <- chol(Sigma) # the decomposition
A
```
```{r}
crossprod(A) # check to see if we get our input back
```
So now we rewrite, but multiply the diffusions by the matrix A to get our correlation as per Cholesky... 
```{r}
set.seed(123)
drift_heston <- c("mu*x1", "kappa*(theta-x2)")
diff_heston <- matrix(c("c11*sqrt(x2)*x1", "0", "c12*sqrt(x2)*x1", "c22*epsilon*sqrt(x2)"),2,2)
heston <- setModel(drift=drift_heston, diffusion=diff_heston, state.var=c("x1","x2"))
X_heston <- simulate(heston, true.par=list(theta=0.1, mu=0.12, kappa=2,epsilon=0.2, c11=A[1,1], c12=A[1,2], c22=A[2,2]), xinit=c(0.1,0.05))
plot(X_heston) #,plot.type="single", col=c("red","blue") <- add this for a laugh
```
Now the QMLE bit for our Heston model...
```{r}
n <- 750
heston_samp <- setSampling(Terminal = n^(1/3), n=n)
yuima_heston <- setYuima(model=heston, sampling = heston_samp)
set.seed(123)
yuima_heston <- simulate(heston, true.parameter = list(theta=0.1, mu=0.12, kappa=2,epsilon=0.2, c11=A[1,1], c12=A[1,2], c22=A[2,2]))
param.init <- list(theta=0.5, mu=0.12, kappa=2,epsilon=0.2, c11=A[1,1], c12=A[1,2], c22=A[2,2])
# +- 1%
low.par <- list(theta=0, mu=0, kappa=0,epsilon=0, c11=A[1,1]*0.99, c12=A[1,2]*0.99, c22=A[2,2]*0.99)
upp.par <- list(theta=1, mu=1, kappa=5,epsilon=1, c11=A[1,1]*1.01, c12=A[1,2]*1.01, c22=A[2,2]*1.01)
mle_heston <- qmle(yuima_heston, start = param.init, lower = low.par, upper = upp.par)
summary(mle_heston)
```

```{r}
logLik(mle_heston)
```

Well that's looking asss suspect as my Python one. Parameter c22 is a bit off? The c12 shows the correlation coefficient well, c11 hasnt changed either. The parameters it gives are just the initial starting values (tested a few different ones). So how do I know its actually doing anything with the parameter values I give it? 

### SABR...(modified heston from above)

$dX_t^{(1)} = X_t^{(2)} X_t^{(1)\beta}dW_t^{(1)}$

$dX_t^{(2)} = \theta_1 X_t^{(2)}dW_t^{(2)}$

where the brownians are correlated by some $\rho$ and lets say that we want to use two independent brownians $B_t^{(1)}$ and $B_t^{(2)}$
In order to do this, we need to transform them Cholesky decomposition (Colin, I used a package here!).

The joint distribution of these things (Y) wants to be bivariate normal with correlation matrix $\Sigma$ s.t. $Y\sim N(0,\Sigma)$. So we use Cholesky to find such a matrix that $A^TA=\Sigma$. Then if Z is the standard multivariate normal, then $AZ \sim N(0,\Sigma)$ in the same way as we change brownians to be $\sqrt{dt}.N(0,1)$ all the time. So if we take the correlation matrix, and get the Cholesky decomp of it to get A, we can transform (multiply in normal speak!) the original diffusion matrix so that it works with independent Brownians.

So the matrix form of the model as it stands is BLAH.
```{r}
rho = 0.7
Sigma <- matrix(c(1.0, rho, rho, 1.0), 2, 2) #I used own values from correlated wieners in python here so S_11 = S_22 = 1 ??
A <- chol(Sigma) # the decomposition
A
```
```{r}
crossprod(A) # check to see if we get our input back
```
```{r}
set.seed(123)
drift_sabr <- c("0", "0")
diff_sabr <- matrix(c("x2*x1^beta*c11", "0", "x2*x1^beta*c12", "alpha*x2*c22"),2,2)
sabr <- setModel(drift=drift_sabr, diffusion=diff_sabr, state.var=c("x1","x2"))
X_sabr <- simulate(sabr, true.parameter=list(alpha=0.1,beta=-0.1, c11=A[1,1], c12=A[1,2], c22=A[2,2]), xinit=c(0.1,0.01))
plot(X_sabr) #,plot.type="single", col=c("red","blue") <- add this for a laugh
```

Now the qMLE bit...
```{r}
n <- 750
sabr_samp <- setSampling(Terminal = n^(1/3), n=n)
yuima_sabr <- setYuima(model=sabr, sampling = sabr_samp)
set.seed(123)
yuima_sabr <- simulate(sabr, true.parameter=list(alpha=0.1,beta=-0.1, c11=A[1,1], c12=A[1,2], c22=A[2,2]))
param.init <- list(alpha=0.1,beta=0.01, c11=A[1,1], c12=A[1,2], c22=A[2,2])
# +- 1% on the covariance matrix or it moans at you
low.par <- list(alpha=0.0,beta=-1, c11=A[1,1]*0.99, c12=A[1,2]*0.99, c22=A[2,2]*0.99)
upp.par <- list(alpha=1.0,beta=1.0, c11=A[1,1]*1.01, c12=A[1,2]*1.01, c22=A[2,2]*1.01)
mle_sabr <- qmle(yuima_sabr, start = param.init, lower = low.par, upper = upp.par)
summary(mle_sabr)
```
Well also as hilarious as mine in Excel! beta started at 0, 

```{r}
logLik(mle_sabr)
```
... there you have it. Even R predicts a pretty wild MLE.

The parameters seem to be just what the guesses are. That behaviour also doesnt seem to affect the MLE thats it gives out. If we set the true $\beta = -0.1$, and guess it as 0, it comes back as 0, for example.

I dont have time to dig into this a whole heap right now, but im curious as to why it behaves that way, but working out whether its a R thing, a YUIMA thing, or the probable 'user error', im not sure. 

## Page 87 of the YUIMA DOCS (colins email) 
$dXt^e = - drift.matrix * Xt^e * dt + diff.matrix * dWt$
```{r}
diff.matrix <- matrix(c("theta1.1","theta1.2", "1", "1"), 2, 2)
drift.c <- c("-theta2.1*x1", "-theta2.2*x2", "-theta2.2", "-theta2.1")
drift.matrix <- matrix(drift.c, 2, 2)

ymodel <- setModel(drift=drift.matrix, diffusion=diff.matrix, time.variable="t",
state.variable=c("x1", "x2"), solve.variable=c("x1", "x2"))
n <- 100
ysamp <- setSampling(Terminal=(n)^(1/3), n=n)
yuima <- setYuima(model=ymodel, sampling=ysamp)
set.seed(123)

#.... from here
##xinit=c(x1, x2) #true.parameter=c(theta2.1, theta2.2, theta1.1, theta1.2)
yuima <- simulate(yuima, xinit=c(1, 1),
true.parameter=list(theta2.1=0.5, theta2.2=0.3, theta1.1=0.6, theta1.2=0.2))
## theta2 <- c(0.8, 0.2) #c(theta2.1, theta2.2) # THIS IS ALL COMMENTED OUT?!
##theta1 <- c(0.7, 0.1) #c(theta1.1, theta1.2)
## QL <- ql(yuima, theta2, theta1, h=1/((n)^(2/3))) #ql is real value of ()? 
## QL
## ## another way of parameter specification
## #param <- list(theta2=theta2, theta1=theta1)
## #QL <- ql(yuima, h=1/((n)^(2/3)), param=param)
## #QL
## theta2.1.lim <- c(0, 1) #c is combine
## theta2.2.lim <- c(0, 1)
## theta1.1.lim <- c(0, 1)
## theta1.2.lim <- c(0, 1)
## theta2.lim <- t( matrix( c(theta2.1.lim, theta2.2.lim), 2, 2) ) #t is transpose
## theta1.lim <- t( matrix( c(theta1.1.lim, theta1.2.lim), 2, 2) )
## system.time(
## opt <- ml.ql(yuima, theta2, theta1, h=1/((n)^(2/3)), theta2.lim, theta1.lim)
## )
## opt@coef
system.time(
opt2 <- qmle(yuima, start=list(theta2.1=0.8, theta2.2=0.2, theta1.1=0.7, theta1.2=0.1),
lower=list(theta1.1=.1,theta1.2=.1,theta2.1=.1,theta2.2=.1),
upper=list(theta1.1=4,theta1.2=4,theta2.1=4,theta2.2=4), method="L-BFGS-B")
)
opt2@coef
summary(opt2)
```
### SABR part 2 (pg81-2 of docs applied to SABR)
Applying the above to SABR

```{r}
rho = -0.7
Sigma <- matrix(c(1.0, rho, rho, 1.0), 2, 2) #I used own values from correlated wieners in python here so S_11 = S_22 = 1 ??
A <- chol(Sigma) # the decomposition

set.seed(123)
drift_sabr <- c("0", "0")
diff_sabr <- matrix(c("x2*x1^beta*c11", "0", "x2*x1^beta*c12", "alpha*x2*c22"),2,2)
sabr <- setModel(drift=drift_sabr, diffusion=diff_sabr, state.var=c("x1","x2"))
X_sabr <- simulate(sabr, true.parameter=list(alpha=0.1,beta=-0.1, c11=A[1,1], c12=A[1,2], c22=A[2,2]), xinit=c(0.1,0.01))
plot(X_sabr) #,plot.type="single", col=c("red","blue") <- add this for a laugh


n <- 750
sabr_samp <- setSampling(Terminal = n^(1/3), n=n)
yuima_sabr <- setYuima(model=sabr, sampling = sabr_samp)
set.seed(123)
yuima_sabr <- simulate(sabr, true.parameter=list(alpha=0.1,beta=-0.1, c11=A[1,1], c12=A[1,2], c22=A[2,2]))

param.init <- list(alpha=0.1,beta=0.01, c11=A[1,1], c12=A[1,2], c22=A[2,2])
low.par <- list(alpha=0.0,beta=-1, c11=A[1,1]*0.99, c12=A[1,2]*0.99, c22=A[2,2]*0.99)
upp.par <- list(alpha=1.0,beta=1.0, c11=A[1,1]*1.01, c12=A[1,2]*1.01, c22=A[2,2]*1.01)
system.time(
opt2 <- qmle(yuima_sabr, start = param.init,lower=low.par, upper = upp.par, method="L-BFGS-B")
)
opt2@coef
summary(opt2)

```
```{r}
opt2
```

```{r}
logLik(opt2)
```
Still consistent with this super large negative result.

## Page 81-2 YUIMA DOCS
(this is where we got wires crossed with docs and book so this is an extra)
A different approach to putting in a 2D model into YUIMA. Its in the poisson.random.sampling method section, but its of the SABR type. Manual classification of the diffusion matrix, so it skips the Cholesky decomp calculation done for previous examples.

$dX_t^{(2)} = X_t^{(2)}(1+t) dW_t^{(2)}$ (book)

$dX_t^{(1)} = X_t^{(1)}\sqrt{(1+t^2)} dW_t^{(1)}$ (book)

$\rho = \sqrt{1+\frac{1}{2}\cos(X_t^{(1)}X_t^{(2)})}$ (book)

The code from pg 81-82 as it is...(with added plot)
```{r}
## Set a model
diff.coef.1 <- function(t, x1=0, x2) x2*(1+t)
diff.coef.2 <- function(t, x1, x2=0) x1*sqrt(1+t^2)
cor.rho <- 0.7 #function(t, x1=0, x2=0) sqrt((1+cos(x1*x2))/2)
# Manual Cholesky matrix: 
diff.coef.matrix <- matrix(c("diff.coef.1(t,x1,x2)","diff.coef.2(t,x1,x2)*cor.rho", "", "diff.coef.2(t,x1,x2)*sqrt(1-cor.rho^2)"),2,2)
cor.mod <- setModel(drift=c("",""), diffusion=diff.coef.matrix, solve.variable=c("x1", "x2"))
set.seed(111)

## Simulate & plot the two dimensional diffusion model
yuima.samp <- setSampling(Terminal=1, n=1200)
yuima <- setYuima(model=cor.mod, sampling=yuima.samp)
yuima <- simulate(yuima, xinit=c(3,2)) 
plot(yuima)
```
### Applied to SABR (docs pg81-2)
Answer looks sensible, I dont think I can apply an MLE here as there are no parameters? So applying this to SABR and adding an MLE... 
```{r}
# Set for SABR
library(yuima) 
cor.rho <- 0.7 
## Set a model
diff.coef.1 <- function(x1, x2,alpha, beta=1) x2 * x1^(beta)
diff.coef.2 <- function(x1, x2, alpha, beta) alpha*x2
diff.coef.matrix <- matrix(c("diff.coef.1(x1, x2, alpha, beta)", "diff.coef.2(x1, x2, alpha, beta)*cor.rho", "", "diff.coef.2(x1, x2, alpha, beta)*sqrt(1-cor.rho^2)"),2,2)
cor.model <- setModel(drift=c("",""), diffusion=diff.coef.matrix, solve.variable=c("x1", "x2"), state.variable=c("x1", "x2"), xinit=c(0.1,0.05))
set.seed(111) 

## We first simulate the two dimensional diffusion model
yuima.samp <- setSampling(Terminal=1, n=1200)
yuima <- setYuima(model=cor.model, sampling=yuima.samp)
# Plot processes...
yuima.sim <- simulate(yuima )
plot(yuima.sim)
#qMLE
yuima <- simulate(cor.model, true.parameter = list(alpha=0.1,beta=0.1) )
param.init <- list(alpha=0.1, beta=-0.1)
low.par <- list(alpha=0.0, beta=-0.5)
upp.par <- list(alpha=0.8, beta=0.5)
mle <- qmle(yuima, start = param.init, lower = low.par, upper = upp.par, method="L-BFGS-B") 
summary(mle) 
```
Flat line on the volatility process - the value is initialised, and ive checked all I can for errors, the process just doesnt vary when it should. 
MLE fails. Hours spent trying to find error - checked as much as I can think of, no luck. 
Abandon ship?

## 3D example YUIMA BOOK pg 81-82
Three SDEs and a g(x) thrown into the second equation, and only 2 Wiener processes.

```{r}
mu <- 0.1
sig <- 0.2
rho <- -0.7
g <- function(t) {0.4 + (0.1 + 0.2*t)* exp(-2*t)}
f1 <- function(t, x1, x2, x3) {
    ret <- 0
    if(x1 > 0 && x2 > 0) ret <- x2*exp(log(x1)*2/3)
    return(ret)
}
f2 <- function(t, x1, x2, x3, rho, sig) {
    ret <- 0
    if(x3 > 0) ret <- rho*sig*x3
    return(ret)
}
f3 <- function(t, x1, x2, x3, rho, sig) {
    ret <- 0
    if(x3 > 0) ret <- sqrt(1-rho^2)*sig*x3
    return(ret)
}
diff.coef.matrix <- matrix(c("f1(t,x1,x2,x3)", "f2(t,x1,x2,x3,rho, sig) * g(t)", "f2(t,x1,x2,x3,rho,sig)", "0", "f3(t,x1,x2,x3,rho,sig)*g(t)", "f3(t,x1,x2,x3,rho,sig)"), 3, 2)

sabr.mod <- setModel(drift = c("0", "mu*g(t)*x3", "mu*x3"), diffusion = diff.coef.matrix, state.variable = c("x1", "x2", "x3"), solve.variable = c("x1", "x2", "x3"),xinit = c(0.1,0.1,0.1))
str(sabr.mod@parameter)

sabr.mod.sim <- simulate(sabr.mod, true.parameter = list(mu=0.1,sigma=0.2,rho=-0.7))
plot(sabr.mod.sim)
diff.coef.matrix
```
```{r}
# Try adding an MLE here as per the heston book example ...
sabr.mod.sampling <- setSampling(Terminal=1, n=1000)
sabr.mod.yuima <- setYuima(model=sabr.mod, sampling = sabr.mod.sampling)
set.seed(123)
sabr.mod.yuima <- simulate(sabr.mod.yuima, xinit = list(0.1,0.1,0.1), true.parameter = list(mu=0.1,sigma=0.2,rho=-0.7))
param.init <- list(mu=0.1,sigma=0.2,rho=-0.7)
low.par <- list(mu=0.0,sigma=0.0,rho=-1)
upp.par <- list(mu=1,sigma=1,rho=1)
mle1 <- qmle(yuima, start = param.init, lower = low.par, upper = upp.par)
summary(mle1)
```
### 3D model reduced to SABR
Ok, so now a 3D model that gives some sort of output. I tried an MLE but it doesnt work, and im not sure how to handle t in g(t). So now lets make a copy and reduce it to be SABR...

```{r}
# Set correlation coefficient
rho <- -0.7
# Set diffusion coefficients for both processes
f1 <- function(x1, x2,alpha, beta) {
    ret <- x2 * x1^beta
    return(ret)
}
f2 <- function(x1, x2, alpha, beta) {
    ret <- alpha * x2
    return(ret)
}
# Create diffusion coefficient matrix as per Cholesky so correlation is achieved
diff.coef.matrix <- matrix(c("f1(x1, x2,alpha, beta)", "f2(x1, x2,alpha, beta) * rho", "0", "f2(x1, x2,alpha, beta)*sqrt(1-rho^2)"), 2, 2)
# Set up model
sabr.mod <- setModel(drift = c("", ""), diffusion = diff.coef.matrix, state.variable = c("x1", "x2"), solve.variable = c("x1", "x2"),xinit = c(0.1,0.1))
str(sabr.mod@parameter)
# Generate simulated data & plot
sabr.mod.sim <- simulate(sabr.mod, true.parameter = list(alpha=0.1,beta=0.1))
plot(sabr.mod.sim)
# Set sampling, create yuima object, set seed, pass yuima object some simulated data
sabr.mod.samp <- setSampling(Terminal=1, n=100)
sabr.mod.yuima <- setYuima(model=sabr.mod, sampling=sabr.mod.samp)
set.seed(123)
sabr.mod.yuima <- simulate(sabr.mod, true.parameter = list(alpha=0.1,beta=0.1), xinit =c(0.05,0.05) )

# Do a least squares estimate...
sabr.mod.lse <- lse(sabr.mod.yuima, start = list(alpha=0.1, beta=-0.1), lower = list(alpha=0.0, beta=-0.5), upper = list(alpha=0.8, beta=0.5),method="L-BFGS-B")
# Feed that output into the quasilog likelihood...
sabr.mod.lse
params=list(alpha = sabr.mod.lse[1],beta = sabr.mod.lse[2])
quasilogl(sabr.mod.yuima,param=params, print=TRUE)

# Do a qMLE: Bounds -0.5 <= beta <= 0.5, 0 < alpha <= 0.8 - seems sensible?
sabr.mod.mle <- qmle(sabr.mod.yuima, start = list(alpha=0.1, beta=-0.1), lower = list(alpha=0.0, beta=-0.5), upper = list(alpha=0.8, beta=0.5),method="L-BFGS-B") 
```
So, the LSE and QUASILOGL work which is interesting, but are presumable not optimised - its just a quasilogl for the parameters I fed it. The qMLE doesnt work due to that last error. Ive scoured the books, and docs, and all of the examples ive followed to the letter aside from the actual models and im not seeing anything out of line. 
 